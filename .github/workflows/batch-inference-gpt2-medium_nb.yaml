name: batch-inference-gpt2-medium_nb

on:
  workflow_dispatch:
  pull_request:
    branches:
      - main
    paths:
      - .github/workflows/batch-inference-gpt2-medium_nb.yaml
env:
  model_name: gpt2-medium
  model_version: 4
jobs:
  batch-inference-gpt2-medium_nb:
    runs-on: self-hosted
    steps:
      - name: azure login
        uses: azure/login@v1
        with:
          creds: ${{secrets.AZ_SYSTEM}}
      - name: run foundation-models/system/inference/text-generation/text-generation-batch-endpoint.ipynb
        run: |
            papermill -k python text-generation-batch-endpoint.ipynb text-generation-batch-endpoint.output.ipynb -p model_name "${{ env.model_name }}" -p model_version "${{ env.model_version }}"
        working-directory: sdk/python/foundation-models/system/inference/text-generation
      - name: upload notebook's working folder as an artifact
        if: ${{ always() }}
        uses: actions/upload-artifact@v2
        with:
          name: text-generation-batch-endpoint
          path: sdk/python/foundation-models/system/inference/text-generation