{
    "queue_name": "test-japaneast-2",
    "models": [
        "MLFlow-TheBloke/vicuna-7B-v1.3-GPTQ",
        "MLFlow-cerebras/Cerebras-GPT-13B",
        "MLFlow-tner/roberta-large-bionlp2004",
        "MLFlow-lvwerra/gpt2-imdb",
        "MLFlow-KoboldAI/OPT-13B-Erebus",
        "MLFlow-EleutherAI/polyglot-ko-5.8b",
        "MLFlow-Helsinki-NLP/opus-mt-no-de",
        "MLFlow-ai-forever/mGPT",
        "MLFlow-csdc-atl/baichuan-7B-chat",
        "MLFlow-bert-large-cased-whole-word-masking-finetuned-squad",
        "MLFlow-bigcode/santacoder",
        "MLFlow-vilsonrodrigues/falcon-7b-instruct-sharded",
        "MLFlow-Helsinki-NLP/opus-mt-vi-en",
        "MLFlow-bigcode/starcoderbase",
        "MLFlow-openlm-research/open_llama_7b",
        "MLFlow-KoboldAI/OPT-2.7B-Erebus",
        "MLFlow-NousResearch/Nous-Hermes-Llama2-13b",
        "MLFlow-cross-encoder/stsb-roberta-large",
        "MLFlow-EleutherAI/pythia-1.4b-deduped",
        "MLFlow-Helsinki-NLP/opus-mt-bat-en",
        "MLFlow-xlm-mlm-100-1280",
        "MLFlow-huggyllama/llama-13b",
        "MLFlow-monologg/biobert_v1.1_pubmed",
        "MLFlow-bigscience/bloom",
        "MLFlow-shahrukhx01/question-vs-statement-classifier",
        "MLFlow-EMBEDDIA/sloberta",
        "MLFlow-benjamin/wtp-bert-mini",
        "MLFlow-databricks/dolly-v2-12b",
        "MLFlow-HooshvareLab/bert-fa-base-uncased",
        "MLFlow-WizardLM/WizardLM-13B-V1.2",
        "MLFlow-HuggingFaceH4/tiny-random-LlamaForCausalLM"
    ],
    "workspace": "test-japaneast",
    "subscription": "80c77c76-74ba-4c8c-8229-4c3b2957990c",
    "resource_group": "huggingface-registry-test1",
    "registry": "HuggingFace",
    "environment": "automate-venv",
    "compute": "Standard-E64s-v3",
    "instance_type": "Standard_E64s_v3"
}