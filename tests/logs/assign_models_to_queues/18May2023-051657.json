{
    "test-australiaeast": {
        "0": [
            "shobhank-iiitdwd-bert-summary",
            "idea-ccnl-randeng-t5-784m-multitask-chinese",
            "wikidepia-indot5-base-paraphrase",
            "gchhablani-fnet-base-finetuned-cola",
            "ctu-aic-mbart25-multilingual-summarization-multilarge-cs",
            "inu-ai-dolly-japanese-gpt-1b",
            "codeparrot-codeparrot-small-multi",
            "koboldai-gpt-j-6b-adventure",
            "helsinki-nlp-opus-mt-de-nl",
            "klue-roberta-small",
            "luodian-llama-7b-hf",
            "helsinki-nlp-opus-mt-fr-de",
            "ckiplab-albert-tiny-chinese-ws",
            "declare-lab-flan-alpaca-large",
            "koboldai-opt-6b-nerys-v2",
            "deepset-bert-medium-squad2-distilled",
            "cl-tohoku-bert-base-japanese",
            "decapoda-research-llama-7b-hf"
        ],
        "1": [
            "idea-ccnl-erlangshen-unimc-albert-235m-english",
            "allenai-tk-instruct-3b-def-pos",
            "mariagrandury-roberta-base-finetuned-sms-spam-detection",
            "adasnew-t5-small-xsum",
            "pszemraj-led-large-book-summary",
            "valhalla-distilbart-mnli-12-6",
            "stanford-crfm-alias-gpt2-small-x21",
            "koboldai-fairseq-dense-2.7b-nerys",
            "ivanlau-language-detection-fine-tuned-on-xlm-roberta-base",
            "sahajtomar-german-zeroshot",
            "flax-community-t5-recipe-generation",
            "helsinki-nlp-opus-mt-gmq-en",
            "sxie3333-roberta",
            "shibing624-macbert4csc-base-chinese",
            "helsinki-nlp-opus-mt-pl-en",
            "helsinki-nlp-opus-mt-nl-en",
            "helsinki-nlp-opus-mt-it-en",
            "helsinki-nlp-opus-mt-de-en"
        ],
        "2": [
            "l3cube-pune-mahahate-bert",
            "google-pegasus-x-large",
            "zixtrauce-johnbot",
            "shitao-retromae-msmarco",
            "idea-ccnl-erlangshen-roberta-110m-nli",
            "unitary-unbiased-toxic-roberta",
            "sonnenblume-bert-base-uncased-ancient-greek-v4",
            "idea-ccnl-wenzhong-gpt2-110m",
            "eleutherai-pythia-1.4b-deduped-v0",
            "yarongef-distilprotbert",
            "eleutherai-pythia-1b",
            "microsoft-minilm-l12-h384-uncased",
            "dbmdz-bert-base-italian-cased",
            "milanlproc-feel-it-italian-sentiment",
            "cardiffnlp-twitter-xlm-roberta-base-sentiment-multilingual",
            "deepset-tinyroberta-squad2",
            "cardiffnlp-twitter-roberta-base-emotion",
            "neulab-codebert-java"
        ]
    },
    "test-australiasoutheast": {
        "0": [
            "l3cube-pune-marathi-ner",
            "uwb-air-czert-b-base-cased",
            "lvwerra-t5-imdb",
            "luyu-co-condenser-wiki",
            "huggingface-course-bert-finetuned-squad",
            "facebook-esm1v-t33-650m-ur90s-2",
            "marco127-dralberto",
            "helsinki-nlp-opus-mt-nl-fr",
            "bigscience-mt0-small",
            "ai-forever-rubert-large",
            "cardiffnlp-twitter-roberta-base-irony",
            "asafaya-bert-base-arabic",
            "ckiplab-albert-tiny-chinese",
            "sxie3333-distilbert",
            "google-t5-v1-1-small",
            "bert-large-uncased-whole-word-masking",
            "microsoft-deberta-xlarge-mnli",
            "mrm8488-t5-base-finetuned-common-gen"
        ],
        "1": [
            "mdraw-german-news-sentiment-bert",
            "xlm-mlm-100-1280",
            "mrsinghania-asr-question-detection",
            "ckiplab-bert-base-chinese-qa",
            "google-bigbird-roberta-large",
            "helsinki-nlp-opus-mt-en-cs",
            "yangheng-deberta-v3-base-absa-v1.1",
            "yikuan8-clinical-longformer",
            "hooshvarelab-distilbert-fa-zwnj-base-ner",
            "s-nlp-russian-toxicity-classifier",
            "yanekyuk-bert-uncased-keyword-extractor",
            "databricks-dolly-v1-6b",
            "cross-encoder-nli-deberta-base",
            "google-mt5-large",
            "alvaroalon2-biobert-diseases-ner",
            "wonrax-phobert-base-vietnamese-sentiment",
            "cerebras-cerebras-gpt-111m",
            "valhalla-longformer-base-4096-finetuned-squadv1"
        ],
        "2": [
            "helsinki-nlp-opus-mt-en-hy",
            "pranavpsv-gpt2-genre-story-generator",
            "lemon234071-t5-base-chinese",
            "idea-ccnl-randeng-t5-77m-multitask-chinese",
            "castorini-monot5-base-msmarco",
            "facebook-esm1v-t33-650m-ur90s-4",
            "togethercomputer-redpajama-incite-instruct-3b-v1",
            "mrm8488-bert-small2bert-small-finetuned-cnn-daily-mail-summarization",
            "google-bigbird-pegasus-large-pubmed",
            "drishtisharma-stablediffusion-prompt-generator-gpt-neo-125m",
            "cardiffnlp-twitter-roberta-base-dec2021-tweet-topic-multi-all",
            "google-pegasus-pubmed",
            "intel-bert-base-uncased-mrpc",
            "j-hartmann-sentiment-roberta-large-english-3-classes",
            "facebook-roberta-hate-speech-dynabench-r4-target",
            "lmsys-vicuna-7b-delta-v0",
            "gustavosta-magicprompt-stable-diffusion",
            "dslim-bert-large-ner"
        ]
    },
    "test-brazilsouth": {
        "0": [
            "helsinki-nlp-opus-mt-mt-en",
            "henryk-bert-base-multilingual-cased-finetuned-dutch-squad2",
            "castorini-doc2query-t5-base-msmarco",
            "allenai-tk-instruct-base-def-pos",
            "beir-query-gen-msmarco-t5-large-v1",
            "facebook-esm1v-t33-650m-ur90s-5",
            "amberoad-bert-multilingual-passage-reranking-msmarco",
            "helsinki-nlp-opus-mt-en-ro",
            "robinhad-ukrainian-qa",
            "facebook-galactica-6.7b",
            "shahrukhx01-bert-mini-finetune-question-detection",
            "tehvenom-ppo-shygmalion-6b",
            "stabilityai-stablelm-base-alpha-3b",
            "facebook-blenderbot-3b",
            "uer-gpt2-chinese-cluecorpussmall",
            "cross-encoder-mmarco-mminilmv2-l12-h384-v1",
            "microsoft-biomednlp-pubmedbert-base-uncased-abstract",
            "dslim-bert-base-ner-uncased"
        ],
        "1": [
            "curiousily-layoutlmv3-financial-document-classification",
            "uer-chinese-roberta-l-8-h-512",
            "consciousai-question-answering-roberta-base-s",
            "nlpaueb-sec-bert-base",
            "mlrs-bertu",
            "uer-gpt2-chinese-lyric",
            "apanc-russian-inappropriate-messages",
            "mrm8488-bert-medium-finetuned-squadv2",
            "allenai-ivila-row-layoutlm-finetuned-s2vl-v2",
            "deepset-gelectra-base-germanquad-distilled",
            "timpal0l-mdeberta-v3-base-squad2",
            "cmarkea-distilcamembert-base",
            "cross-encoder-stsb-roberta-base",
            "facebook-nllb-200-1.3b",
            "tehvenom-dolly-shygmalion-6b",
            "salesforce-codet5-base",
            "dccuchile-bert-base-spanish-wwm-cased",
            "bert-large-uncased-whole-word-masking-finetuned-squad"
        ],
        "2": [
            "bigscience-bloom-7b1-petals",
            "ninedaywang-polycoder-0.4b",
            "mlrs-mbertu",
            "akshatsurolia-icd-10-code-prediction",
            "sismetanin-rubert-ru-sentiment-rusentiment",
            "maryaai-opus-mt-en-ar-finetuned-math-13-10-en-to-ar",
            "diptanu-fbert",
            "facebook-xlm-roberta-xl",
            "cross-encoder-stsb-tinybert-l-4",
            "manishiitg-resume-ner",
            "xhan77-ssdlm",
            "rinna-japanese-gpt2-medium",
            "yahma-llama-7b-hf",
            "microsoft-xtremedistil-l6-h256-uncased",
            "facebook-nllb-200-distilled-600m",
            "helsinki-nlp-opus-mt-tc-big-en-pt",
            "facebook-esm2-t6-8m-ur50d",
            "nlptown-bert-base-multilingual-uncased-sentiment"
        ]
    },
    "test-canadacentral": {
        "0": [
            "activebus-bert-review",
            "jean-baptiste-roberta-large-financial-news-sentiment-en",
            "lightonai-rita-s",
            "liam168-c4-zh-distilbert-base-uncased",
            "google-t5-large-ssm-nqo",
            "codeparrot-codeparrot-small",
            "bergum-xtremedistil-l6-h384-go-emotion",
            "allenai-unifiedqa-t5-small",
            "cardiffnlp-bertweet-base-hate",
            "luhua-chinese-pretrain-mrc-macbert-large",
            "ckiplab-bert-base-chinese",
            "koboldai-gpt-neo-2.7b-shinen",
            "klue-roberta-large",
            "microsoft-deberta-large",
            "ahotrod-electra-large-discriminator-squad2-512",
            "human-centered-summarization-financial-summarization-pegasus",
            "hfl-chinese-bert-wwm-ext",
            "neuralmind-bert-base-portuguese-cased"
        ],
        "1": [
            "thunlp-lawformer",
            "shahules786-blade2blade-t5-base",
            "thanathorn-mt5-cpe-kmutt-thai-sentence-sum",
            "junnyu-roformer-chinese-sim-char-small",
            "togethercomputer-redpajama-incite-instruct-7b-v0.1",
            "meli-gpt2-prompt",
            "bhadresh-savani-bert-base-uncased-emotion",
            "philschmid-bert-banking77",
            "tau-splinter-base",
            "fnlp-cpt-base",
            "tuner007-pegasus-qa",
            "microsoft-deberta-v2-xxlarge-mnli",
            "vamsi-t5-paraphrase-paws",
            "fnlp-bart-base-chinese",
            "cross-encoder-nli-roberta-base",
            "deepset-roberta-large-squad2",
            "tehvenom-ppo-pygway-v8p4-dev-6b",
            "emilyalsentzer-bio-clinicalbert"
        ],
        "2": [
            "jiaqilee-imdb-finetuned-bert-base-uncased",
            "hf-internal-testing-tiny-random-rembertfortokenclassification",
            "microsoft-prophetnet-large-uncased-squad-qg",
            "cointegrated-rut5-base",
            "salesforce-bart-large-xsum-samsum",
            "crabz-slovakbert-ner",
            "dtai-kuleuven-robbert-v2-dutch-sentiment",
            "parth-result",
            "uer-gpt2-chinese-poem",
            "hf-internal-testing-tiny-random-bloom",
            "liam168-trans-opus-mt-zh-en",
            "seyonec-chemberta-zinc-base-v1",
            "nateraw-bert-base-uncased-emotion",
            "unitary-toxic-bert",
            "alvaroalon2-biobert-chemical-ner",
            "cross-encoder-ms-marco-tinybert-l-2",
            "lvwerra-distilbert-imdb",
            "papluca-xlm-roberta-base-language-detection"
        ]
    },
    "test-canadaeast": {
        "0": [
            "xlm-roberta-large-finetuned-conll02-dutch",
            "moritzlaurer-deberta-v3-base-mnli-fever-docnli-ling-2c",
            "ainize-kobart-news",
            "trl-internal-testing-tiny-bloomforcausallm-correct-vocab",
            "bigscience-bloomz-petals",
            "morit-xlm-t-full-xnli",
            "anakin87-electra-italian-xxl-cased-squad-it",
            "mrm8488-bert-tiny-finetuned-sms-spam-detection",
            "bioformers-bioformer-16l",
            "ai-forever-rut5-base",
            "yiyanghkust-finbert-fls",
            "declare-lab-flan-alpaca-base",
            "cogcomp-bart-faithful-summary-detector",
            "facebook-wmt19-de-en",
            "textattack-bert-base-uncased-yelp-polarity",
            "google-mt5-base",
            "kredor-punctuate-all",
            "j-hartmann-emotion-english-distilroberta-base"
        ],
        "1": [
            "cardiffnlp-twitter-roberta-base-2022-154m",
            "mbzuai-lamini-gpt-1.5b",
            "t-systems-onsite-mt5-small-sum-de-en-v2",
            "ml6team-mt5-small-german-query-generation",
            "ilyagusev-rubertconv-toxic-clf",
            "helsinki-nlp-opus-mt-eo-en",
            "prithivida-informal-to-formal-styletransfer",
            "hakurei-lit-6b",
            "mrm8488-distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es",
            "salesforce-codegen-6b-multi",
            "bigscience-bloomz-1b1",
            "bert-base-cased-finetuned-mrpc",
            "voidful-context-only-question-generator",
            "togethercomputer-pythia-chat-base-7b",
            "microsoft-dialogpt-large",
            "helsinki-nlp-opus-mt-en-ru",
            "martin-ha-toxic-comment-model",
            "prithivida-parrot-paraphraser-on-t5"
        ],
        "2": [
            "gogamza-kobart-summarization",
            "mingzhong-dialogled-large-5120",
            "jihuai-bert-ancient-chinese",
            "microsoft-dialogrpt-human-vs-machine",
            "uer-roberta-base-finetuned-jd-binary-chinese",
            "nreimers-mminilmv2-l6-h384-distilled-from-xlmr-large",
            "aubmindlab-bert-base-arabertv02-twitter",
            "dmis-lab-biobert-large-cased-v1.1-squad",
            "google-byt5-xl",
            "etalab-ia-camembert-base-squadfr-fquad-piaf",
            "textattack-bert-base-uncased-ag-news",
            "microsoft-dialogrpt-updown",
            "klue-roberta-base",
            "mrm8488-bert-spanish-cased-finetuned-pos-16-tags",
            "cardiffnlp-twitter-xlm-roberta-base",
            "cardiffnlp-tweet-topic-21-multi",
            "huggingface-codeberta-small-v1",
            "madhurjindal-autonlp-gibberish-detector-492513457"
        ]
    },
    "test-centralindia": {
        "0": [
            "hf-internal-testing-mrpc-bert-base-cased",
            "helsinki-nlp-opus-mt-de-fr",
            "intel-t5-small-xsum-int8-dynamic",
            "ixa-ehu-scibert-squad-quac",
            "moritzlaurer-deberta-v3-base-mnli-fever-anli",
            "jhu-clsp-bibert-ende",
            "hugherinit-hi",
            "cmarkea-distilcamembert-base-ner",
            "djagatiya-ner-roberta-base-ontonotesv5-englishv4",
            "dbmdz-bert-base-italian-uncased",
            "cardiffnlp-twitter-roberta-base-hate",
            "eleutherai-pythia-410m-deduped",
            "it5-it5-base-news-summarization",
            "soleimanian-financial-roberta-large-sentiment",
            "facebook-wmt19-ru-en",
            "vennify-t5-base-grammar-correction",
            "eleutherai-gpt-neo-2.7b",
            "gpt2-medium"
        ],
        "1": [
            "llukas22-all-minilm-l12-v2-qa-en",
            "yurtsai-yurts-python-code-gen-30-sparse",
            "rostlab-prot-t5-base-mt-uniref50",
            "milanlproc-xlm-emo-t",
            "circulus-kobart-trans-en-ko-v2",
            "circulus-kobart-trans-ko-en-v2",
            "microsoft-deberta-xlarge",
            "codeparrot-codeparrot",
            "google-electra-base-generator",
            "gronlp-hatebert",
            "microsoft-godel-v1-1-base-seq2seq",
            "facebook-mbart-large-50-many-to-one-mmt",
            "dandelin-vilt-b32-mlm",
            "hello-simpleai-chatgpt-detector-roberta",
            "blanchefort-rubert-base-cased-sentiment-rusentiment",
            "helsinki-nlp-opus-mt-en-romance",
            "prithivida-parrot-adequacy-model",
            "cl-tohoku-bert-base-japanese-whole-word-masking"
        ],
        "2": [
            "helsinki-nlp-opus-mt-en-mk",
            "koboldai-gpt-neo-1.3b-adventure",
            "nghuyong-ernie-3.0-xbase-zh",
            "hit-tmg-dialogue-bart-large-chinese",
            "anonymous-german-nlp-german-gpt2",
            "idea-ccnl-randeng-pegasus-523m-summary-chinese",
            "thomassimonini-t5-end2end-question-generation",
            "vietai-gpt-j-6b-vietnamese-news",
            "facebook-opt-iml-1.3b",
            "helsinki-nlp-opus-mt-ine-en",
            "albert-xxlarge-v1",
            "helsinki-nlp-opus-mt-en-fi",
            "hfl-chinese-bert-wwm",
            "hfl-chinese-roberta-wwm-ext-large",
            "facebook-nllb-200-distilled-1.3b",
            "microsoft-mpnet-base",
            "valhalla-distilbart-mnli-12-1",
            "philschmid-bart-large-cnn-samsum"
        ]
    },
    "test-centralus": {
        "0": [
            "alger-ia-dziribert",
            "alexandrainst-da-discourse-coherence-base",
            "aubmindlab-aragpt2-large",
            "marcosgg-bert-base-gl-cased",
            "zixtrauce-baekbot",
            "amansolanki-autonlp-tweet-sentiment-extraction-20114061",
            "alimazhar-110-website-classification",
            "bigscience-mt0-base",
            "moritzlaurer-deberta-v3-xsmall-mnli-fever-anli-ling-binary",
            "rinna-japanese-gpt2-small",
            "seyonec-pubchem10m-smiles-bpe-450k",
            "deepset-xlm-roberta-large-squad2",
            "salesforce-codegen-2b-multi",
            "google-electra-small-generator",
            "facebook-xlm-v-base",
            "bert-base-german-cased",
            "ismail-lucifer011-autotrain-company-all-903429548",
            "cardiffnlp-twitter-xlm-roberta-base-sentiment"
        ],
        "1": [
            "aubmindlab-bert-base-arabertv01",
            "flaubert-flaubert-large-cased",
            "juierror-flan-t5-text2sql-with-schema",
            "helsinki-nlp-opus-mt-bg-en",
            "prachipatel-text-results",
            "thomasnlg-t5-qa-squad2neg-en",
            "batterydata-batterybert-cased-squad-v1",
            "helsinki-nlp-opus-mt-th-en",
            "helsinki-nlp-opus-mt-en-hi",
            "tweebanknlp-bertweet-tb2-ewt-pos-tagging",
            "facebook-galactica-1.3b",
            "helsinki-nlp-opus-mt-ko-en",
            "deepset-gbert-large",
            "humarin-chatgpt-paraphraser-on-t5-base",
            "helsinki-nlp-opus-mt-da-en",
            "kamalkraj-bioelectra-pico",
            "ismail-lucifer011-autotrain-job-all-903929564",
            "prosusai-finbert"
        ],
        "2": [
            "philschmid-instruct-igel-001",
            "obi-deid-bert-i2b2",
            "ckiplab-albert-base-chinese-pos",
            "seyonec-pubchem10m-smiles-bpe-60k",
            "liyuan-amazon-review-sentiment-analysis",
            "naver-efficient-splade-v-large-doc",
            "seyonec-pubchem10m-smiles-bpe-396-250",
            "persiannlp-mt5-large-parsinlu-opus-translation-fa-en",
            "manishiitg-distilbert-resume-parts-classify",
            "microsoft-xtremedistil-l6-h384-uncased",
            "sbcbi-sentiment-analysis",
            "declare-lab-flan-alpaca-xl",
            "bigscience-bloomz-1b7",
            "onlplab-alephbert-base",
            "pdelobelle-robbert-v2-dutch-base",
            "cl-tohoku-bert-base-japanese-char-v2",
            "ismail-lucifer011-autotrain-name-all-904029577",
            "facebook-bart-large-cnn"
        ]
    },
    "test-eastasia": {
        "0": [
            "nbailab-nb-bert-base-mnli",
            "intel-dynamic-tinybert",
            "j-hartmann-emotion-english-roberta-large",
            "microsoft-biomednlp-pubmedbert-large-uncased-abstract",
            "ku-nlp-deberta-v2-large-japanese",
            "snunlp-kr-finbert-sc",
            "seyonec-smiles-tokenized-pubchem-shard00-160k",
            "keti-air-ke-t5-base",
            "helsinki-nlp-opus-mt-en-sq",
            "sander-wood-text-to-music",
            "bigscience-bloomz-3b",
            "bigscience-mt0-large",
            "csebuetnlp-mt5-multilingual-xlsum",
            "ufal-robeczech-base",
            "milanlproc-feel-it-italian-emotion",
            "helsinki-nlp-opus-mt-sv-en",
            "facebook-mbart-large-50",
            "bert-large-uncased"
        ],
        "1": [
            "sshleifer-student-marian-en-ro-6-1",
            "helsinki-nlp-opus-mt-tc-big-fi-en",
            "aychang-roberta-base-imdb",
            "uclanlp-plbart-java-cs",
            "mrm8488-t5-base-finetuned-imdb-sentiment",
            "mbzuai-lamini-flan-t5-783m",
            "ckiplab-bert-tiny-chinese",
            "microsoft-biomedvlp-cxr-bert-general",
            "helsinki-nlp-opus-mt-sl-uk",
            "sshleifer-tiny-ctrl",
            "ml6team-keyphrase-extraction-kbir-inspec",
            "facebook-xglm-1.7b",
            "snrspeaks-keyphrasetransformer",
            "dbmdz-bert-base-german-cased",
            "helsinki-nlp-opus-mt-en-sv",
            "monologg-koelectra-small-v2-distilled-korquad-384",
            "xlnet-base-cased",
            "jean-baptiste-camembert-ner"
        ],
        "2": [
            "microsoft-tapex-base",
            "svalabs-gbert-large-zeroshot-nli",
            "chanind-frame-semantic-transformer-base",
            "satvikag-chatbot",
            "michiyasunaga-biolinkbert-large",
            "timpal0l-xlm-roberta-base-faq-extractor",
            "ai-forever-fred-t5-large",
            "helsinki-nlp-opus-mt-roa-en",
            "helsinki-nlp-opus-mt-es-de",
            "xlm-mlm-en-2048",
            "helsinki-nlp-opus-mt-no-de",
            "cointegrated-rubert-tiny",
            "helsinki-nlp-opus-mt-hi-en",
            "rjuro-scinertopic",
            "albert-xxlarge-v2",
            "facebook-opt-2.7b",
            "stanfordaimi-stanford-deidentifier-base",
            "yiyanghkust-finbert-tone"
        ]
    },
    "test-eastus2": {
        "0": [
            "ninedaywang-polycoder-160m",
            "jdchang-t5-10-bc",
            "vocab-transformers-distilbert-word2vec-256k-mlm-best",
            "microsoft-dialogrpt-depth",
            "sshleifer-distilbart-xsum-12-6",
            "koboldai-gpt-j-6b-janeway",
            "benjamin-gerpt2-large",
            "cross-encoder-quora-distilroberta-base",
            "helsinki-nlp-opus-mt-uk-en",
            "cl-tohoku-bert-large-japanese",
            "cardiffnlp-twitter-roberta-base-hate-latest",
            "michaelrglass-albert-base-rci-wikisql-row",
            "lmsys-fastchat-t5-3b-v1.0",
            "mingzhong-unieval-sum",
            "bert-base-german-dbmdz-uncased",
            "textattack-bert-base-uncased-sts-b",
            "klue-bert-base",
            "distilgpt2"
        ],
        "1": [
            "nghuyong-ernie-3.0-medium-zh",
            "hf-internal-testing-tiny-random-rembertforcausallm",
            "hfl-rbt6",
            "eistakovskii-xlm-roberta-base-multilingual-toxicity-classifier-plus",
            "neuralspace-reverie-indic-transformers-hi-bert",
            "cambridgeltl-sst-mobilebert-uncased",
            "hfl-chinese-lert-base",
            "aubmindlab-aragpt2-base",
            "stanford-crfm-biomedlm",
            "yiyanghkust-finbert-pretrain",
            "google-bigbird-pegasus-large-arxiv",
            "hyunwoongko-kobart",
            "studio-ousia-luke-base",
            "valhalla-distilbart-mnli-12-3",
            "sbcbi-sentiment-analysis-model",
            "textattack-roberta-base-cola",
            "bigscience-bloomz-7b1",
            "seethal-sentiment-analysis-generic-dataset"
        ],
        "2": [
            "mrm8488-t5-small-finetuned-emotion",
            "openmatch-cocodr-base-msmarco",
            "mrm8488-bert-italian-finedtuned-squadv1-it-alfa",
            "fav-kky-fernet-c5",
            "mywateriswet-shuanbot",
            "alexkay-xlm-roberta-large-qa-multilingual-finedtuned-ru",
            "w11wo-indonesian-roberta-base-sentiment-classifier",
            "ehartford-wizardlm-7b-uncensored",
            "idea-ccnl-randeng-pegasus-238m-summary-chinese",
            "helsinki-nlp-opus-mt-vi-en",
            "deepset-xlm-roberta-base-squad2-distilled",
            "helsinki-nlp-opus-mt-gem-gem",
            "connorboyle-bert-ner-i2b2",
            "sagorsarker-bangla-bert-base",
            "albert-base-v1",
            "citizenlab-twitter-xlm-roberta-base-sentiment-finetunned",
            "cross-encoder-ms-marco-tinybert-l-2-v2",
            "camembert-base"
        ]
    },
    "test-francecentral": {
        "0": [
            "dbmdz-bert-small-historic-multilingual-cased",
            "hf-internal-testing-tiny-random-rembertforquestionanswering",
            "tehvenom-gpt-j-pyg-ppo-6b-dev-v8p4",
            "castorini-afriberta-large",
            "clarin-pl-fastpdn",
            "s-nlp-roberta-toxicity-classifier",
            "helsinki-nlp-opus-mt-hu-en",
            "smilegate-ai-kor-unsmile",
            "tuner007-pegasus-summarizer",
            "flaubert-flaubert-small-cased",
            "helsinki-nlp-opus-mt-da-de",
            "microsoft-promptist",
            "microsoft-godel-v1-1-large-seq2seq",
            "google-t5-v1-1-xl",
            "helsinki-nlp-opus-mt-ca-es",
            "ai-forever-ruroberta-large",
            "facebook-opt-125m",
            "deepset-roberta-base-squad2"
        ],
        "1": [
            "51la5-roberta-large-ner",
            "hf-internal-testing-tiny-random-rembertforsequenceclassification",
            "hf-internal-testing-tiny-random-ctrllmheadmodel",
            "ganjinzero-biobart-large",
            "juierror-text-to-sql-with-table-schema",
            "facebook-xglm-7.5b",
            "cahya-distilbert-base-indonesian",
            "bert-large-cased-whole-word-masking",
            "hfl-rbt3",
            "norahalshahrani-bertmsda",
            "oliverguhr-fullstop-punctuation-multilingual-base",
            "google-mt5-xl",
            "openassistant-reward-model-deberta-v3-large-v2",
            "valhalla-t5-small-e2e-qg",
            "microsoft-dialogpt-small",
            "textattack-bert-base-uncased-mnli",
            "finiteautomata-beto-sentiment-analysis",
            "gpt2-large"
        ],
        "2": [
            "tanrei-gptsan-japanese",
            "iacopo-shakespear-gpt2",
            "facebook-esm1b-t33-650m-ur50s",
            "sshleifer-distilbart-xsum-1-1",
            "mfeb-albert-xxlarge-v2-squad2",
            "microsoft-tapex-base-finetuned-wtq",
            "mrm8488-bert2bert-shared-spanish-finetuned-summarization",
            "cointegrated-roberta-large-cola-krishna2020",
            "helsinki-nlp-opus-mt-ca-en",
            "facebook-blenderbot-90m",
            "nlpcloud-instruct-gpt-j-fp16",
            "kblab-bert-base-swedish-cased",
            "pierreguillou-lilt-xlm-roberta-base-finetuned-with-doclaynet-base-at-linelevel-ml384",
            "bhadresh-savani-albert-base-v2-emotion",
            "helsinki-nlp-opus-mt-de-es",
            "facebook-blenderbot-400m-distill",
            "helsinki-nlp-opus-mt-en-de",
            "bigcode-santacoder"
        ]
    },
    "test-germanywestcentral": {
        "0": [
            "turkunlp-gpt3-finnish-small",
            "nytk-puli-gpt-2",
            "valhalla-s2t-mustc-multilinguial-medium",
            "unicamp-dl-translation-en-pt-t5",
            "vinai-phobert-base-v2",
            "facebook-blenderbot-1b-distill",
            "allenai-wmt19-de-en-6-6-base",
            "eleutherai-polyglot-ko-3.8b",
            "helsinki-nlp-opus-mt-uk-sl",
            "stanfordaimi-stanford-deidentifier-only-i2b2",
            "rucaibox-mvp",
            "thatdramebaazguy-roberta-base-squad",
            "kes-t5-kes",
            "helsinki-nlp-opus-mt-ja-en",
            "yale-lily-brio-cnndm-uncased",
            "entropy-roberta-zinc-480m",
            "sultan-biom-electra-large-squad2",
            "helsinki-nlp-opus-mt-en-es"
        ],
        "1": [
            "cardiffnlp-twitter-roberta-base-emotion-multilabel-latest",
            "uer-gpt2-distil-chinese-cluecorpussmall",
            "zhihan1996-dna-bert-3",
            "potsawee-t5-large-generation-squad-questionanswer",
            "sijunhe-nezha-cn-base",
            "kaludi-reviews-sentiment-analysis",
            "koboldai-gpt-j-6b-skein",
            "helsinki-nlp-opus-mt-cs-en",
            "thebloke-vicuna-7b-1.1-hf",
            "thebloke-wizardlm-7b-hf",
            "kssteven-ibert-roberta-base",
            "valhalla-t5-small-qa-qg-hl",
            "law-ai-inlegalbert",
            "stabilityai-stablelm-tuned-alpha-3b",
            "snrspeaks-t5-one-line-summary",
            "philschmid-distilbart-cnn-12-6-samsum",
            "gronlp-bert-base-dutch-cased",
            "davlan-distilbert-base-multilingual-cased-ner-hrl"
        ],
        "2": [
            "ilyagusev-fred-t5-ru-turbo-alpaca",
            "ncfrey-chemgpt-1.2b",
            "sonnenblume-bert-base-uncased-ancient-greek-v3",
            "naltukhov-joke-generator-rus-t5",
            "helsinki-nlp-opus-mt-es-it",
            "clueai-chatyuan-large-v1",
            "atharvamundada99-bert-large-question-answering-finetuned-legal",
            "allenai-primera",
            "facebook-incoder-1b",
            "eachadea-vicuna-7b-1.1",
            "tner-roberta-large-ontonotes5",
            "flaubert-flaubert-base-cased",
            "pygmalionai-pygmalion-2.7b",
            "nlpaueb-bert-base-greek-uncased-v1",
            "neuralmind-bert-large-portuguese-cased",
            "kwoncho-ko-sroberta-multitask-suspicious",
            "tuner007-pegasus-paraphrase",
            "cardiffnlp-twitter-roberta-base-sentiment-latest"
        ]
    },
    "test-japaneast": {
        "0": [
            "linydub-bart-large-samsum",
            "hf-internal-testing-tiny-random-rembertformaskedlm",
            "philschmid-lilt-en-funsd",
            "hooshvarelab-albert-fa-zwnj-base-v2",
            "keti-air-ke-t5-small",
            "casehold-custom-legalbert",
            "hfl-chinese-xlnet-base",
            "camel-lab-bert-base-arabic-camelbert-mix-ner",
            "helsinki-nlp-opus-mt-ar-de",
            "patrickvonplaten-led-large-16384-pubmed",
            "deepset-gelectra-large-germanquad",
            "plantl-gob-es-roberta-base-bne",
            "dkleczek-bert-base-polish-uncased-v1",
            "airesearch-wangchanberta-base-att-spm-uncased",
            "facebook-bart-large-xsum",
            "facebook-opt-6.7b",
            "helsinki-nlp-opus-mt-ar-en",
            "bert-base-chinese"
        ],
        "1": [
            "kodiks-news-category-classification-turkish",
            "plantl-gob-es-roberta-large-bne-capitel-ner",
            "elnaggarlab-ankh-large",
            "gchhablani-fnet-base-finetuned-sst2",
            "hz53-bert-base-uncased-cb",
            "cltl-medroberta.nl",
            "rajkumarrrk-gpt2-fine-tuned-on-imdb-positive-reviews",
            "koboldai-gpt-neo-2.7b-horni-ln",
            "aleksickx-llama-7b-hf",
            "salti-bert-base-multilingual-cased-finetuned-squad",
            "ahmetayrnc-distilroberta-base",
            "facebook-blenderbot-small-90m",
            "ai-forever-rugpt3large-based-on-gpt2",
            "salesforce-codegen-2b-mono",
            "valhalla-t5-base-qa-qg-hl",
            "textattack-bert-base-uncased-sst-2",
            "microsoft-deberta-v3-base",
            "t5-small"
        ],
        "2": [
            "teomotun-finetuning-sentiment-model-for-c2er",
            "pysentimiento-robertuito-base-uncased",
            "hf-internal-testing-tiny-random-ctrlforsequenceclassification",
            "facebook-npm-single",
            "philschmid-distilbert-base-multilingual-cased-sentiment-2",
            "xlm-mlm-xnli15-1024",
            "sshleifer-distill-pegasus-xsum-16-4",
            "sshleifer-distilbart-cnn-12-3",
            "michiyasunaga-biolinkbert-base",
            "modeltc-bert-base-uncased-mrpc",
            "chainyo-alpaca-lora-7b",
            "google-byt5-base",
            "lvwerra-gpt2-imdb",
            "dbmdz-german-gpt2",
            "camel-lab-bert-base-arabic-camelbert-da-sentiment",
            "prithivida-parrot-fluency-model",
            "facebook-opt-1.3b",
            "dslim-bert-base-ner"
        ]
    },
    "test-japanwest": {
        "0": [
            "cl-tohoku-bert-base-japanese-char-whole-word-masking",
            "helsinki-nlp-opus-mt-tc-big-he-en",
            "ck46-t5-base-hotpot-qa-qg",
            "savasy-bert-base-turkish-sentiment-cased",
            "crumb-bloom-560m-rlhf-sd2-prompter-aesthetic",
            "nlp-waseda-roberta-base-japanese",
            "alekseykorshuk-vicuna-7b",
            "oliverguhr-fullstop-punctuation-multilingual-sonar-base",
            "stevhliu-my-awesome-billsum-model",
            "microsoft-prophetnet-large-uncased",
            "helsinki-nlp-opus-mt-gmw-gmw",
            "roberta-large-openai-detector",
            "jjzha-jobbert-base-cased",
            "lidiya-bart-large-xsum-samsum",
            "alexjercan-codet5-base-buggy-error-description",
            "valhalla-t5-base-e2e-qg",
            "deepset-bert-large-uncased-whole-word-masking-squad2",
            "bigscience-bloom-560m"
        ],
        "1": [
            "pysentimiento-roberta-es-sentiment",
            "deep-learning-analytics-wikihow-t5-small",
            "ar4ikov-gpt2-medium-650k-stable-diffusion-prompt-generator",
            "allenai-tk-instruct-3b-def",
            "helsinki-nlp-opus-mt-de-fi",
            "idea-ccnl-erlangshen-deberta-v2-320m-chinese",
            "apanc-russian-sensitive-topics",
            "automatic-promptgen-majinai-safe",
            "uer-roberta-base-chinese-extractive-qa",
            "iarfmoose-bert-base-cased-qa-evaluator",
            "helsinki-nlp-opus-mt-fi-de",
            "helsinki-nlp-opus-mt-it-es",
            "koboldai-gpt-neo-2.7b-horni",
            "nferruz-protgpt2",
            "cointegrated-rubert-tiny-toxicity",
            "mel-iza0-zero-shot",
            "facebook-m2m100-1.2b",
            "cardiffnlp-twitter-roberta-base-sentiment"
        ],
        "2": [
            "andreasmadsen-efficient-mlm-m0.40",
            "ibm-knowgl-large",
            "helsinki-nlp-opus-mt-eu-en",
            "pierreguillou-t5-base-qa-squad-v1.1-portuguese",
            "ar4ikov-gpt2-650k-stable-diffusion-prompt-generator",
            "google-byt5-large",
            "vietai-gpt-neo-1.3b-vietnamese-news",
            "plantl-gob-es-roberta-base-biomedical-clinical-es",
            "fnlp-bart-large-chinese",
            "tehvenom-gpt-j-pyg-ppo-6b",
            "cross-encoder-qnli-electra-base",
            "cross-encoder-stsb-roberta-large",
            "camel-lab-bert-base-arabic-camelbert-ca-pos-egy",
            "bigscience-t0-3b",
            "fredzhang7-distilgpt2-stable-diffusion-v2",
            "mrm8488-t5-base-finetuned-span-sentiment-extraction",
            "bhadresh-savani-distilbert-base-uncased-emotion",
            "facebook-bart-large-mnli"
        ]
    },
    "test-koreacentral": {
        "0": [
            "mbzuai-lamini-flan-t5-248m",
            "elozano-bert-base-cased-clickbait-news",
            "rsvp-ai-bertserini-bert-base-squad",
            "dcu-nlp-bert-base-irish-cased-v1",
            "pritamdeka-biobert-pubmed200krct",
            "helsinki-nlp-opus-mt-da-es",
            "lcampillos-roberta-es-clinical-trials-ner",
            "idb-ita-gilberto-uncased-from-camembert",
            "gagan3012-k2t-base",
            "google-tapas-large-finetuned-wtq",
            "cardiffnlp-twitter-roberta-base",
            "facebook-wmt19-en-ru",
            "eleutherai-pythia-6.9b-deduped",
            "helsinki-nlp-opus-mt-id-en",
            "dbmdz-bert-base-german-uncased",
            "koboldai-opt-6.7b-erebus",
            "kykim-bertshared-kor-base",
            "distilbert-base-uncased-finetuned-sst-2-english"
        ],
        "1": [
            "emelnov-t5-summarization-g-b",
            "plantl-gob-es-roberta-large-bne",
            "michelecafagna26-t5-base-finetuned-sst2-sentiment",
            "pierreguillou-bert-large-cased-squad-v1.1-portuguese",
            "idea-ccnl-erlangshen-tcbert-330m-sentence-embedding-chinese",
            "siku-bert-sikubert",
            "amandakonet-climatebert-fact-checking",
            "stevhliu-my-awesome-model",
            "cerebras-cerebras-gpt-590m",
            "valhalla-distilbart-mnli-12-9",
            "pygmalionai-pygmalion-1.3b",
            "uclanlp-plbart-base",
            "textattack-albert-base-v2-rotten-tomatoes",
            "hivemind-gpt-j-6b-8bit",
            "bigscience-bloomz-7b1-mt",
            "t5-3b",
            "facebook-m2m100-418m",
            "distilroberta-base"
        ],
        "2": [
            "lmqg-t5-small-tweetqa-qa",
            "helsinki-nlp-opus-mt-cy-en",
            "dennlinger-roberta-cls-consec",
            "textattack-roberta-base-mnli",
            "pszemraj-bigbird-pegasus-large-k-booksum",
            "cardiffnlp-xlm-twitter-politics-sentiment",
            "typeform-squeezebert-mnli",
            "eleutherai-pythia-1b-deduped-v0",
            "cristian-popa-bart-tl-ng",
            "eleutherai-pythia-6.9b-deduped-v0",
            "staka-fugumt-en-ja",
            "microsoft-deberta-v3-xsmall",
            "eleutherai-pythia-1.4b-deduped",
            "nlpaueb-legal-bert-base-uncased",
            "microsoft-biogpt",
            "bigscience-bloomz-560m",
            "microsoft-deberta-large-mnli",
            "albert-base-v2"
        ]
    },
    "test-northcentralus": {
        "0": [
            "zongqianli-matbert-base-cased",
            "huggingface-codeberta-language-id",
            "bhadresh-savani-distilbert-base-uncased-go-emotion",
            "paulagarciaserrano-roberta-depression-detection",
            "mingzhong-unieval-fact",
            "helsinki-nlp-opus-mt-sv-uk",
            "uklfr-gottbert-base",
            "neko-institute-of-science-pygmalion-7b",
            "helsinki-nlp-opus-mt-de-ar",
            "iarfmoose-t5-base-question-generator",
            "togethercomputer-gpt-jt-moderation-6b",
            "cross-encoder-nli-deberta-v3-base",
            "allenai-unifiedqa-t5-base",
            "helsinki-nlp-opus-mt-af-en",
            "obi-deid-roberta-i2b2",
            "heegyu-gpt2-emotion",
            "bert-base-multilingual-uncased",
            "roberta-large"
        ],
        "1": [
            "mrm8488-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es",
            "google-t5-large-ssm",
            "helsinki-nlp-opus-mt-sv-fi",
            "ckiplab-albert-base-chinese-ws",
            "castorini-afriberta-base",
            "deeppavlov-rudialogpt3-medium-based-on-gpt2-v2",
            "oliverguhr-fullstop-dutch-punctuation-prediction",
            "cardiffnlp-twitter-roberta-base-sep2022",
            "cointegrated-rut5-base-absum",
            "eleutherai-pythia-1.4b",
            "pygmalionai-pygmalion-350m",
            "salesforce-codegen-350m-nl",
            "m3rg-iitd-matscibert",
            "sxie3333-xlnet",
            "google-pegasus-large",
            "openai-gpt",
            "cl-tohoku-bert-base-japanese-char",
            "distilbert-base-multilingual-cased"
        ],
        "2": [
            "snorkelai-sdnet",
            "b3ck1-gpt-neo-125m-finetuned-beer-recipes",
            "yuanzhoulvpi-gpt2-chinese",
            "climatebert-distilroberta-base-climate-f",
            "helsinki-nlp-opus-mt-sk-en",
            "sonoisa-t5-base-japanese-title-generation",
            "it5-it5-large-news-summarization",
            "dumitrescustefan-bert-base-romanian-cased-v1",
            "allenai-unifiedqa-v2-t5-large-1363200",
            "bloom-testing-test-bloomd-560m-a47152861e4132c9080d4f84ba87c7a58f556a2f997765c1f9fc9a40c4b643f3",
            "wietsedv-bert-base-dutch-cased",
            "damapika-electra-base-discriminator-squad-mod",
            "allenai-led-large-16384",
            "einmalumdiewelt-t5-base-gnad",
            "distilbert-base-german-cased",
            "ckiplab-bert-base-chinese-pos",
            "google-flan-t5-small",
            "bert-base-multilingual-cased"
        ]
    },
    "test-northeurope": {
        "0": [
            "alenusch-rugpt3-paraphraser",
            "flax-community-gpt-2-spanish",
            "plantl-gob-es-bsc-bio-ehr-es",
            "mayagalvez-bert-base-multilingual-cased-finetuned-pos",
            "dbmdz-convbert-base-turkish-mc4-uncased",
            "surdan-labse-ner-nerel",
            "coppercitylabs-uzbert-base-uncased",
            "shahrukhx01-roberta-base-boolq",
            "monologg-biobert-v1.1-pubmed",
            "declare-lab-flan-alpaca-gpt4-xl",
            "microsoft-deberta-base-mnli",
            "damapika-distilbert-base-uncased-mod",
            "moritzlaurer-mdeberta-v3-base-mnli-xnli",
            "microsoft-graphcodebert-base",
            "koboldai-opt-2.7b-erebus",
            "rostlab-prot-bert",
            "oliverguhr-german-sentiment-bert",
            "microsoft-deberta-base"
        ],
        "1": [
            "salesforce-codegen-2b-nl",
            "deepesp-gpt2-spanish",
            "helsinki-nlp-opus-mt-fi-sv",
            "valhalla-t5-small-qg-hl",
            "bert-base-german-dbmdz-cased",
            "google-roberta2roberta-l-24-cnn-daily-mail",
            "facebook-esm1v-t33-650m-ur90s-1",
            "textattack-roberta-base-sst-2",
            "salesforce-codegen-6b-mono",
            "yjernite-bart-eli5",
            "helsinki-nlp-opus-mt-en-nl",
            "wajidlinux99-gibberish-text-detector",
            "eleutherai-pythia-2.8b-deduped",
            "facebook-mbart-large-cc25",
            "cardiffnlp-twitter-roberta-base-offensive",
            "microsoft-mdeberta-v3-base",
            "roberta-base-openai-detector",
            "xlm-roberta-large"
        ],
        "2": [
            "ku-nlp-roberta-base-japanese-char-wwm",
            "liamliang-demographics-gender",
            "beomi-korean-hatespeech-multilabel",
            "camembert-camembert-base",
            "microsoft-git-base-vatex",
            "facebook-esm2-t36-3b-ur50d",
            "ckiplab-albert-tiny-chinese-pos",
            "jackaduma-secbert",
            "mariorossi-t5-base-finetuned-question-answering",
            "amphora-finabsa",
            "pinkmanlove-llama-7b-hf",
            "helsinki-nlp-opus-mt-et-en",
            "sociocom-medner-cr-ja",
            "salesforce-codegen-350m-multi",
            "helsinki-nlp-opus-mt-en-ar",
            "helsinki-nlp-opus-mt-mul-en",
            "helsinki-nlp-opus-mt-en-fr",
            "bert-base-cased"
        ]
    },
    "test-norwayeast": {
        "0": [
            "jjzha-jobbert-knowledge-extraction",
            "hz53-bert-base-uncased-wic",
            "kmewhort-stable-diffusion-prompt-bolster",
            "cross-encoder-nli-deberta-v3-xsmall",
            "pierreguillou-gpt2-small-portuguese",
            "helsinki-nlp-opus-mt-tc-big-en-tr",
            "turkunlp-bert-base-finnish-uncased-v1",
            "ilyagusev-rubert-ext-sum-gazeta",
            "pin-senda",
            "typeform-mobilebert-uncased-mnli",
            "finiteautomata-bertweet-base-emotion-analysis",
            "damapika-roberta-base-mod",
            "sileod-deberta-v3-base-tasksource-nli",
            "eleutherai-pythia-160m-deduped",
            "kirili4ik-mbart-rudialogsum",
            "naver-splade-cocondenser-ensembledistil",
            "rohanrajpal-bert-base-multilingual-codemixed-cased-sentiment",
            "t5-base"
        ],
        "1": [
            "dtai-kuleuven-robbert-2022-dutch-base",
            "dahoas-pythia-125m-static-sft",
            "shaina-covid-qa-mpnet",
            "microsoft-tapex-large-finetuned-wtq",
            "pierreguillou-ner-bert-large-cased-pt-lenerbr",
            "aekupor-revoicing",
            "dataintelligenceteam-documentclassifier",
            "blanchefort-rubert-base-cased-sentiment",
            "textattack-bert-base-uncased-imdb",
            "arampacha-roberta-tiny",
            "gustavosta-magicprompt-dalle",
            "microsoft-dialogrpt-human-vs-rand",
            "ynie-roberta-large-snli-mnli-fever-anli-r1-r2-r3-nli",
            "charsiu-g2p-multilingual-byt5-small-100",
            "nbroad-esg-bert",
            "deepset-minilm-uncased-squad2",
            "flexudy-t5-base-multi-sentence-doctor",
            "distilbert-base-uncased"
        ],
        "2": [
            "gagan3012-k2t",
            "norod78-hebrew-bad-wiki-gpt-neo-tiny",
            "tabbyml-j-350m",
            "ckip-joint-bloom-1b1-zh",
            "maltehb-aelaectra-danish-electra-small-cased-ner-dane",
            "it5-it5-efficient-small-el32-news-summarization",
            "wangrongsheng-minigpt-4-llama-7b",
            "vinai-phobert-large",
            "cerebras-cerebras-gpt-256m",
            "deep-learning-analytics-grammarcorrector",
            "pszemraj-led-base-book-summary",
            "kb-bert-base-swedish-cased-ner",
            "tae898-emoberta-large",
            "elron-bleurt-tiny-512",
            "digit82-kobart-summarization",
            "google-pegasus-cnn-dailymail",
            "distilbert-base-uncased-distilled-squad",
            "bert-base-uncased"
        ]
    },
    "test-southafricanorth": {
        "0": [
            "pszemraj-pegasus-x-large-book-summary",
            "facebook-esm-1b",
            "taeminlee-kogpt2",
            "scite-roberta-base-squad2-nq-bioasq",
            "rogerkam-roberta-rcade-fine-tuned-sentiment-covid-news",
            "helsinki-nlp-opus-mt-en-jap",
            "maltehb-danish-bert-botxo",
            "larryvrh-mt5-translation-ja-zh",
            "uw-madison-yoso-4096",
            "microsoft-tapex-large",
            "google-t5-efficient-tiny",
            "jsylee-scibert-scivocab-uncased-finetuned-ner",
            "csarron-bert-base-uncased-squad-v1",
            "prithivida-grammar-error-correcter-v1",
            "koboldai-ppo-pygway-6b-mix",
            "tsmatz-xlm-roberta-ner-japanese",
            "mrm8488-t5-base-finetuned-summarize-news",
            "roberta-base"
        ],
        "1": [
            "helsinki-nlp-opus-mt-en-bg",
            "davlan-afro-xlmr-large",
            "davlan-xlm-roberta-large-ner-hrl",
            "helsinki-nlp-opus-mt-tc-big-en-fr",
            "merry-aid-neo-125m",
            "helsinki-nlp-opus-mt-uk-sv",
            "nsi319-legal-pegasus",
            "neuraly-bert-base-italian-cased-sentiment",
            "eleutherai-pythia-160m-deduped-v0",
            "jimypbr-bert-base-uncased-squad",
            "eleutherai-pythia-410m",
            "fredzhang7-anime-anything-promptgen-v2",
            "automatic-promptgen-lexart",
            "bigscience-bloom-1b7",
            "beomi-kcbert-base",
            "vinai-bertweet-covid19-base-uncased",
            "ramsrigouthamg-t5-sentence-paraphraser",
            "xlm-roberta-base"
        ],
        "2": [
            "emelnov-t5-tags-g-b",
            "jaehyeong-koelectra-base-v3-generalized-sentiment-analysis",
            "qiliang-bart-large-cnn-samsum-electrifai-v10",
            "michaelrglass-albert-base-rci-wikisql-col",
            "google-bigbird-base-trivia-itc",
            "aekupor-adding-on",
            "girinlp-i2i-phibert-finetuned-ner",
            "asahi417-tner-xlm-roberta-large-all-english",
            "bigscience-bloom-petals",
            "helsinki-nlp-opus-mt-en-id",
            "deepset-electra-base-squad2",
            "eleutherai-pythia-2.8b-deduped-v0",
            "cross-encoder-nli-distilroberta-base",
            "ml6team-keyphrase-extraction-distilbert-inspec",
            "langboat-mengzi-bert-base",
            "michellejieli-emotion-text-classifier",
            "michellejieli-nsfw-text-classifier",
            "gpt2"
        ]
    },
    "test-southcentralus": {
        "0": [
            "emelnov-t5-title-g-b",
            "alisawuffles-roberta-large-wanli",
            "alexandrainst-da-hatespeech-detection-small",
            "czearing-article-title-generator",
            "suva-uptag-keyphrase-model",
            "monologg-distilkobert",
            "ubc-nlp-marbert",
            "kykim-albert-kor-base",
            "michiyasunaga-linkbert-large",
            "kblab-bert-base-swedish-lowermix-reallysimple-ner",
            "nreimers-mminilmv2-l12-h384-distilled-from-xlmr-large",
            "elkulako-cryptobert",
            "fabiochiu-t5-small-medium-title-generation",
            "facebook-wmt19-en-de",
            "salesforce-codet5-base-multi-sum",
            "hfl-chinese-roberta-wwm-ext",
            "oliverguhr-fullstop-punctuation-multilang-large"
        ],
        "1": [
            "vietai-vit5-base",
            "jjzha-jobbert-skill-extraction",
            "helsinki-nlp-opus-mt-hr-sv",
            "rifky-indobert-indolem-uncased-qa",
            "helsinki-nlp-opus-mt-en-hu",
            "aekupor-probing",
            "transformersbook-pegasus-samsum",
            "nlpaueb-bert-base-uncased-contracts",
            "avishvj-biobert-protein-ner",
            "alirezamsh-small100",
            "bvanaken-clinical-assertion-negation-bert",
            "rinna-japanese-gpt-1b",
            "dbmdz-bert-base-italian-xxl-cased",
            "deepset-deberta-v3-base-squad2",
            "helsinki-nlp-opus-mt-en-it",
            "mizuiro-sakura-luke-japanese-base-finetuned-ner",
            "google-flan-t5-base"
        ],
        "2": [
            "aitslab-biobert-huner-disease-v1",
            "ntas-charles-dickens-gpt2",
            "helsinki-nlp-opus-mt-en-vi",
            "dumitrescustefan-bert-base-romanian-uncased-v1",
            "allenai-primera-multi-lexsum-source-short",
            "rinna-japanese-gpt2-xsmall",
            "xlm-roberta-large-finetuned-conll03-german",
            "akdeniz27-bert-base-turkish-cased-ner",
            "ktrapeznikov-albert-xlarge-v2-squad-v2",
            "jb2k-bert-base-multilingual-cased-language-detection",
            "microsoft-multilingual-minilm-l12-h384",
            "cross-encoder-nli-deberta-v3-small",
            "allenai-led-base-16384",
            "sxie3333-bert",
            "babylm-t5-base-strict",
            "mrm8488-distilroberta-finetuned-financial-news-sentiment-analysis",
            "distilbert-base-cased-distilled-squad"
        ]
    },
    "test-eastus": {
        "0": [
            "jy46604790-fake-news-bert-detect",
            "ibm-re2g-reranker-nq",
            "nghuyong-ernie-1.0-base-zh",
            "jarvisx17-japanese-sentiment-analysis",
            "arthur-lima-layoutlmv3-triagem-documentos",
            "batterydata-bde-pos-bert-cased-base",
            "ganjinzero-biobart-v2-large",
            "dmitrypogrebnoy-meddistilbertbaserucased",
            "togethercomputer-redpajama-incite-chat-3b-v1",
            "ltg-norbert2",
            "beomi-koalpaca-polyglot-5.8b",
            "koboldai-gpt-j-6b-shinen",
            "ahotrod-albert-xxlargev1-squad2-512",
            "google-t5-xl-lm-adapt",
            "bigscience-bloom-1b1",
            "rakib-roberta-base-on-cuad",
            "eleutherai-gpt-neo-125m"
        ],
        "1": [
            "helsinki-nlp-opus-mt-es-ar",
            "microsoft-dialogrpt-width",
            "davlan-xlm-roberta-large-masakhaner",
            "helsinki-nlp-opus-mt-tl-en",
            "ilyagusev-rut5-base-sum-gazeta",
            "aekupor-connecting",
            "beomi-kcbert-large",
            "mrm8488-t5-base-finetuned-squadv2",
            "koboldai-fairseq-dense-6.7b-shinen",
            "nlptown-flaubert-small-cased-sentiment",
            "recogs-recogs-model",
            "gchhablani-bert-base-cased-finetuned-cola",
            "deepset-deberta-v3-large-squad2",
            "bigscience-bloom-3b",
            "eleutherai-pythia-70m-deduped",
            "google-byt5-small",
            "helsinki-nlp-opus-mt-en-zh"
        ],
        "2": [
            "aidenh20-dnabert-500down",
            "koboldai-gpt-neo-2.7b-janeway",
            "tinkoff-ai-rudialogpt-medium",
            "cointegrated-rubert-tiny-sentiment-balanced",
            "mrm8488-longformer-base-4096-finetuned-squadv2",
            "moussakam-barthez",
            "idea-ccnl-erlangshen-roberta-110m-sentiment",
            "rajkumarrrk-t5-common-gen",
            "eleutherai-pythia-410m-deduped-v0",
            "hooshvarelab-bert-fa-base-uncased-sentiment-digikala",
            "helsinki-nlp-opus-mt-es-fr",
            "helsinki-nlp-opus-mt-bat-en",
            "transfo-xl-wt103",
            "felflare-bert-restore-punctuation",
            "nbailab-nb-bert-base",
            "google-pegasus-xsum",
            "dmis-lab-biobert-base-cased-v1.2"
        ]
    },
    "test-swedencentral": {
        "0": [
            "hetpandya-t5-base-tapaco",
            "deutsche-telekom-bert-multi-english-german-squad2",
            "mrm8488-bert-tiny-finetuned-squadv2",
            "hfl-chinese-lert-small",
            "facebook-mgenre-wiki",
            "ckiplab-gpt2-base-chinese",
            "gerulata-slovakbert",
            "pi3141-dialogpt-medium-elon-3",
            "google-tapas-base-finetuned-sqa",
            "neulab-codebert-python",
            "facebook-esm2-t12-35m-ur50d",
            "eleutherai-polyglot-ko-5.8b",
            "helsinki-nlp-opus-mt-fr-es",
            "recognai-bert-base-spanish-wwm-cased-xnli",
            "helsinki-nlp-opus-mt-tr-en",
            "microsoft-dialogpt-medium",
            "helsinki-nlp-opus-mt-ru-en"
        ],
        "1": [
            "geinitz-gpt2-medium-hemingway",
            "allenai-unifiedqa-v2-t5-large-1251000",
            "ninedaywang-polycoder-2.7b",
            "google-t5-large-ssm-nq",
            "mrm8488-t5-base-finetuned-emotion",
            "skt-ko-gpt-trinity-1.2b-v0.5",
            "line-corporation-line-distilbert-base-japanese",
            "dlicari-italian-legal-bert",
            "bioformers-bioformer-8l",
            "jordyvl-biobert-base-cased-v1.2-ncbi-disease-softmax-labelall-ner",
            "vietai-envit5-translation",
            "cointegrated-rubert-tiny2-cedr-emotion-detection",
            "deepset-roberta-base-squad2-distilled",
            "moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7",
            "knkarthick-meeting-summary",
            "indolem-indobert-base-uncased",
            "nlpaueb-legal-bert-small-uncased"
        ],
        "2": [
            "nlpconnect-roberta-base-squad2-nq",
            "alexwortega-instruct-rugptlarge",
            "nlphust-ner-vietnamese-electra-base",
            "unicamp-dl-ptt5-base-portuguese-vocab",
            "whaleloops-keptlongformer",
            "intel-distilbert-base-uncased-finetuned-sst-2-english-int8-static",
            "daspartho-text-emotion",
            "ai-forever-fred-t5-1.7b",
            "oliverguhr-spelling-correction-english-base",
            "geotrend-distilbert-base-es-cased",
            "saattrupdan-nbailab-base-ner-scandi",
            "dbmdz-bert-base-italian-xxl-uncased",
            "camel-lab-bert-base-arabic-camelbert-mix",
            "xlm-clm-ende-1024",
            "typeform-distilbert-base-uncased-mnli",
            "shahrukhx01-question-vs-statement-classifier",
            "microsoft-deberta-v2-xlarge"
        ]
    },
    "test-switzerlandnorth": {
        "0": [
            "l3cube-pune-hing-bert",
            "phiyodr-bert-base-finetuned-squad2",
            "asi-gpt-fr-cased-base",
            "nlpodyssey-bert-multilingual-uncased-geo-countries-headlines",
            "gargam-roberta-base-crest",
            "uclanlp-plbart-python-en-xx",
            "deepset-gbert-base-germandpr-reranking",
            "monologg-kobigbird-bert-base",
            "ganjinzero-biobart-v2-base",
            "sshleifer-distilbart-cnn-6-6",
            "microsoft-biogpt-large",
            "xlnet-large-cased",
            "kykim-bert-kor-base",
            "textattack-distilbert-base-cased-cola",
            "deepset-bert-base-cased-squad2",
            "xlm-roberta-large-finetuned-conll03-english",
            "microsoft-deberta-v2-xxlarge"
        ],
        "1": [
            "imxly-t5-copy",
            "hf-internal-testing-tiny-random-debertav2fortokenclassification",
            "zixtrauce-bdbot4epoch",
            "idea-ccnl-randeng-bart-139m-summary",
            "langboat-mengzi-t5-base",
            "koboldai-gpt-neo-2.7b-aid",
            "stancld-longt5-tglobal-large-16384-pubmed-3k-steps",
            "facebook-xglm-564m",
            "kit-nlp-bert-base-japanese-sentiment-irony",
            "tscholak-1wnr382e",
            "abeja-gpt-neox-japanese-2.7b",
            "castorini-monot5-3b-msmarco-10k",
            "nghuyong-ernie-3.0-base-zh",
            "microsoft-infoxlm-base",
            "eleutherai-pythia-70m",
            "vicgalle-xlm-roberta-large-xnli-anli",
            "gpt2-xl"
        ],
        "2": [
            "thu-coai-roberta-base-cold",
            "bloomberg-keybart",
            "twmkn9-distilroberta-base-squad2",
            "voidful-albert-chinese-tiny",
            "ainize-bart-base-cnn",
            "ilyagusev-mbart-ru-sum-gazeta",
            "google-long-t5-tglobal-large",
            "pierreguillou-bert-base-cased-squad-v1.1-portuguese",
            "dimitriz-greek-media-bert-base-uncased",
            "cross-encoder-ms-marco-minilm-l-2-v2",
            "xenova-sponsorblock-small",
            "albert-large-v2",
            "babelscape-rebel-large",
            "mmg-xlm-roberta-large-ner-spanish",
            "hfl-chinese-macbert-base",
            "facebook-opt-350m",
            "helsinki-nlp-opus-mt-es-en"
        ]
    },
    "test-uaenorth": {
        "0": [
            "urukhan-t5-russian-spell",
            "hf-internal-testing-tiny-random-debertav2forquestionanswering",
            "fredzhang7-danbooru-tag-generator",
            "cointegrated-rut5-base-paraphraser",
            "thomasnlg-t5-qg-squad1-en",
            "google-long-t5-tglobal-xl",
            "aktsvigun-electra-large-cola",
            "hfl-chinese-macbert-large",
            "m3hrdadfi-typo-detector-distilbert-en",
            "samuel-fipps-t5-efficient-large-nl36-fine-tune-sum-v2",
            "hooshvarelab-bert-fa-base-uncased",
            "ramsrigouthamg-t5-paraphraser",
            "uer-chinese-roberta-l-12-h-768",
            "succinctly-text2image-prompt-generator",
            "google-mt5-small",
            "finiteautomata-bertweet-base-sentiment-analysis",
            "cross-encoder-ms-marco-minilm-l-6-v2"
        ],
        "1": [
            "neko-institute-of-science-llama-7b-hf",
            "helsinki-nlp-opus-mt-en-uk",
            "helsinki-nlp-opus-mt-en-el",
            "yeungnlp-firefly-1b4",
            "ckiplab-albert-base-chinese-ner",
            "hooshvarelab-bert-fa-zwnj-base",
            "beir-query-gen-msmarco-t5-base-v1",
            "bigscience-bigscience-small-testing",
            "stevenlimcorn-indonesian-roberta-base-emotion-classifier",
            "yiyanghkust-finbert-esg-9-categories",
            "google-long-t5-local-base",
            "bert-large-cased-whole-word-masking-finetuned-squad",
            "eleutherai-pythia-2.8b",
            "cl-tohoku-bert-base-japanese-v2",
            "mrm8488-bert-spanish-cased-finetuned-ner",
            "ckiplab-bert-base-chinese-ws",
            "uer-albert-base-chinese-cluecorpussmall"
        ],
        "2": [
            "consciousai-question-answering-roberta-base-s-v2",
            "hf-internal-testing-tiny-random-debertav2formaskedlm",
            "google-t5-efficient-mini",
            "microsoft-tapex-large-finetuned-wikisql",
            "koheiduck-bert-japanese-finetuned-sentiment",
            "cmarkea-distilcamembert-base-sentiment",
            "izumi-lab-bert-small-japanese",
            "asi-gpt-fr-cased-small",
            "qwant-fralbert-base",
            "allenai-t5-small-squad2-question-generation",
            "twmkn9-albert-base-v2-squad2",
            "bigwiz83-sapbert-from-pubmedbert-squad2",
            "google-t5-large-lm-adapt",
            "rinna-japanese-roberta-base",
            "mrm8488-t5-base-finetuned-question-generation-ap",
            "vinai-bertweet-base",
            "google-flan-t5-large"
        ]
    },
    "test-uksouth": {
        "0": [
            "moussakam-arabart",
            "helsinki-nlp-opus-mt-it-de",
            "helsinki-nlp-opus-mt-tc-big-en-ar",
            "togethercomputer-redpajama-incite-chat-7b-v0.1",
            "twitter-twhin-bert-base",
            "aitslab-biobert-huner-species-v1",
            "cahya-xlm-roberta-base-indonesian-ner",
            "lordtt13-emo-mobilebert",
            "bigscience-mt0-xl",
            "ku-nlp-deberta-v2-tiny-japanese-char-wwm",
            "facebook-esm2-t30-150m-ur50d",
            "moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli",
            "microsoft-codebert-base-mlm",
            "huggyllama-llama-7b",
            "aubmindlab-bert-base-arabert",
            "eleutherai-gpt-neo-1.3b",
            "google-flan-t5-xl"
        ],
        "1": [
            "tribbiani-vicuna-7b",
            "hf-internal-testing-tiny-random-debertav2forsequenceclassification",
            "helsinki-nlp-opus-mt-en-roa",
            "csebuetnlp-banglat5-banglaparaphrase",
            "allenai-macaw-large",
            "yoshitomo-matsubara-bert-base-uncased-mnli",
            "camel-lab-bert-base-arabic-camelbert-msa",
            "bertin-project-bertin-roberta-base-spanish",
            "plguillou-t5-base-fr-sum-cnndm",
            "facebook-xmod-base",
            "philschmid-flan-t5-base-samsum",
            "emilyalsentzer-bio-discharge-summary-bert",
            "google-tapas-base-finetuned-wtq",
            "moussakam-frugalscore-tiny-bert-base-bert-score",
            "vblagoje-bert-english-uncased-finetuned-pos",
            "cross-encoder-ms-marco-minilm-l-12-v2",
            "moussakam-barthez-orangesum-abstract"
        ],
        "2": [
            "emelnov-keyt5-tags-custom",
            "helsinki-nlp-opus-mt-en-af",
            "salesforce-grappa-large-jnt",
            "helsinki-nlp-opus-mt-wa-en",
            "s-nlp-roberta-base-formality-ranker",
            "reginaboateng-bert-for-finacial-triples",
            "uer-roberta-base-finetuned-chinanews-chinese",
            "valhalla-t5-small-qg-prepend",
            "russiannlp-ruroberta-large-rucola",
            "nreimers-minilmv2-l6-h384-distilled-from-bert-large",
            "automatic-promptgen-majinai-unsafe",
            "samrawal-bert-base-uncased-clinical-ner",
            "camel-lab-bert-base-arabic-camelbert-mix-pos-msa",
            "google-long-t5-tglobal-base",
            "babelscape-wikineural-multilingual-ner",
            "wietsedv-xlm-roberta-base-ft-udpos28-en",
            "microsoft-infoxlm-large"
        ]
    },
    "test-ukwest": {
        "0": [
            "shibing624-bart4csc-base-chinese",
            "studio-ousia-luke-japanese-base-lite",
            "sultan-arabict5-base",
            "transquest-monotransquest-da-multilingual",
            "uer-roberta-base-finetuned-jd-full-chinese",
            "ktrapeznikov-biobert-v1.1-pubmed-squad-v2",
            "has-abi-distilbert-finetuned-resumes-sections",
            "vinai-bertweet-large",
            "narsil-deberta-large-mnli-zero-cls",
            "it5-it5-large-question-generation",
            "eleutherai-polyglot-ko-1.3b",
            "google-tapas-small-finetuned-wtq",
            "m-polignano-uniba-bert-uncased-l-12-h-768-a-12-italian-alb3rt0",
            "indolem-indobertweet-base-uncased",
            "salesforce-codegen-350m-mono",
            "qiliang-bart-large-cnn-samsum-chatgpt-v3",
            "helsinki-nlp-opus-mt-fr-en"
        ],
        "1": [
            "wietsedv-bert-base-dutch-cased-finetuned-udlassy-ner",
            "textattack-albert-base-v2-imdb",
            "textattack-distilbert-base-uncased-cola",
            "nchunlp-chinese-question-answering",
            "maryaai-opus-mt-ar-en-finetuned-ar-to-en",
            "aekupor-model-utterance",
            "marcosgg-bert-small-gl-cased",
            "ahmedrachid-financialbert-sentiment-analysis",
            "jaynlp-t5-large-samsum",
            "csarron-mobilebert-uncased-squad-v2",
            "uclanlp-visualbert-vqa",
            "aubmindlab-bert-base-arabertv2",
            "hyunwoongko-ctrlsum-cnndm",
            "dominguesm-bert-restore-punctuation-ptbr",
            "beyond-genius-large-k2t",
            "dccuchile-bert-base-spanish-wwm-uncased",
            "bert-large-cased"
        ],
        "2": [
            "helsinki-nlp-opus-mt-tc-big-fr-en",
            "hf-internal-testing-tiny-random-albertfortokenclassification",
            "ethanyt-guwenbert-base",
            "stanfordaimi-radbert",
            "mbartolo-roberta-large-synqa-ext",
            "aekupor-eliciting",
            "helsinki-nlp-opus-mt-it-fr",
            "musixmatch-umberto-commoncrawl-cased-v1",
            "fabiochiu-t5-base-tag-generation",
            "pszemraj-long-t5-tglobal-base-16384-book-summary",
            "ai-forever-rubert-base",
            "eleutherai-pythia-1b-deduped",
            "cross-encoder-stsb-distilroberta-base",
            "classla-bcms-bertic-ner",
            "pszemraj-grammar-synthesis-small",
            "deepset-roberta-base-squad2-covid",
            "neulab-codebert-cpp"
        ]
    },
    "test-westcentralus": {
        "0": [
            "koboldai-fairseq-dense-125m",
            "hf-internal-testing-tiny-random-albertformaskedlm",
            "cahya-bert-base-indonesian-522m",
            "modeltc-bert-base-uncased-qqp",
            "gchhablani-fnet-base-finetuned-mrpc",
            "ai4bharat-indicner",
            "ai-forever-rut5-large",
            "cointegrated-rut5-base-multitask",
            "sagorsarker-codeswitch-hineng-ner-lince",
            "daspartho-prompt-extend",
            "google-pegasus-newsroom",
            "tals-albert-xlarge-vitaminc-mnli",
            "hooshvarelab-bert-base-parsbert-ner-uncased",
            "facebook-mbart-large-50-one-to-many-mmt",
            "michau-t5-base-en-generate-headline",
            "koboldai-opt-6.7b-nerybus-mix",
            "mrm8488-bert-multi-cased-finetuned-xquadv1"
        ],
        "1": [
            "cross-encoder-ms-marco-tinybert-l-6",
            "aubmindlab-bert-large-arabertv02",
            "microsoft-deberta-v2-xlarge-mnli",
            "alexandrainst-da-hatespeech-detection-base",
            "davlan-afro-xlmr-base",
            "cahya-xlm-roberta-large-indonesian-ner",
            "monohime-rubert-base-cased-sentiment-new",
            "allenai-unifiedqa-t5-large",
            "hyunwoongko-asian-bart-ecjk",
            "idea-ccnl-wenzhong2.0-gpt2-3.5b-chinese",
            "ramsrigouthamg-t5-squad-v1",
            "yiyanghkust-finbert-esg",
            "vblagoje-bart-lfqa",
            "ckiplab-bert-base-chinese-ner",
            "finiteautomata-beto-emotion-analysis",
            "roberta-large-mnli",
            "helsinki-nlp-opus-mt-zh-en"
        ],
        "2": [
            "elron-bleurt-large-512",
            "hf-internal-testing-tiny-random-albertforsequenceclassification",
            "plantl-gob-es-gpt2-large-bne",
            "toddgoldfarb-cadet-tiny",
            "daisymak-bert-finetuned-squad-accelerate-10epoch-transformerfrozen",
            "af-ai-center-bert-base-swedish-uncased",
            "ilyagusev-rugpt3medium-sum-gazeta",
            "microsoft-sportsbert",
            "bloom-testing-test-bloomd-560m-db788ae2594f597e839fb48fedb0895f04d853006df99f79d446b6b29c715eb7",
            "facebook-galactica-125m",
            "salesforce-codet5-large-ntp-py",
            "cerebras-cerebras-gpt-1.3b",
            "lmsys-vicuna-7b-delta-v1.1",
            "google-t5-v1-1-large",
            "bhadresh-savani-roberta-base-emotion",
            "helsinki-nlp-opus-mt-romance-en",
            "siebert-sentiment-roberta-large-english"
        ]
    },
    "test-westeurope": {
        "0": [
            "alexandrainst-da-binary-emotion-classification-base",
            "dennlinger-bert-wiki-paragraphs",
            "alexandrainst-da-sentiment-base",
            "clueai-promptclue-base",
            "aloxatel-bert-base-mnli",
            "optimalscale-gpt-neo2.7b-inst-tuning",
            "nielsr-layoutlmv2-finetuned-funsd",
            "facebook-muppet-roberta-large",
            "ku-nlp-deberta-v2-base-japanese",
            "richielo-small-e-czech-finetuned-ner-wikiann",
            "saibo-legal-roberta-base",
            "eleutherai-pythia-6.9b",
            "jean-baptiste-camembert-ner-with-dates",
            "fran-martinez-scibert-scivocab-cased-ner-jnlpba",
            "vinai-phobert-base",
            "microsoft-deberta-v3-large",
            "d4data-biomedical-ner-all"
        ],
        "1": [
            "elnaggarlab-ankh-base",
            "hf-internal-testing-tiny-random-albertforquestionanswering",
            "deepset-bert-base-uncased-squad2",
            "tomh-toxigen-roberta",
            "alan-turing-institute-mt5-large-finetuned-mnli-xtreme-xnli",
            "imsypp-hate-speech-en",
            "mrm8488-codebert-base-finetuned-stackoverflow-ner",
            "togethercomputer-redpajama-incite-base-3b-v1",
            "google-bigbird-pegasus-large-bigpatent",
            "facebook-mbart-large-en-ro",
            "facebook-esm2-t33-650m-ur50d",
            "helsinki-nlp-opus-mt-gem-en",
            "google-t5-base-lm-adapt",
            "elastic-distilbert-base-cased-finetuned-conll03-english",
            "facebook-mbart-large-50-many-to-many-mmt",
            "mingzhong-dialogled-base-16384",
            "bigscience-bloom-7b1"
        ],
        "2": [
            "smanjil-german-medbert",
            "hf-internal-testing-tiny-random-xglmforcausallm",
            "togethercomputer-redpajama-incite-base-7b-v0.1",
            "microsoft-codereviewer",
            "philschmid-tiny-bert-sst2-distilled",
            "deep-learning-analytics-automatic-title-generation",
            "batterydata-bde-cner-batteryonlybert-uncased-base",
            "ramsrigouthamg-t5-boolean-questions",
            "avichr-hebert",
            "cross-encoder-ms-marco-minilm-l-4-v2",
            "dbmdz-electra-large-discriminator-finetuned-conll03-english",
            "hate-speech-cnerg-bert-base-uncased-hatexplain",
            "ai-forever-mgpt",
            "turkunlp-bert-base-finnish-cased-v1",
            "luyu-co-condenser-marco",
            "joeddav-distilbert-base-uncased-go-emotions-student",
            "davlan-bert-base-multilingual-cased-ner-hrl"
        ]
    },
    "test-westus": {
        "0": [
            "hfl-rbtl3",
            "textattack-bert-base-uncased-cola",
            "elinas-llama-7b-hf-transformers-4.29",
            "eugenesiow-bart-paraphrase",
            "helsinki-nlp-opus-mt-fr-ru",
            "helsinki-nlp-opus-mt-ht-en",
            "asahi417-tner-xlm-roberta-base-ontonotes5",
            "hooshvarelab-bert-base-parsbert-uncased",
            "joeddav-bart-large-mnli-yahoo-answers",
            "cross-encoder-nli-minilm2-l6-h768",
            "flaubert-flaubert-base-uncased",
            "cerebras-cerebras-gpt-2.7b",
            "aubmindlab-bert-base-arabertv02",
            "tscholak-cxmefzzi",
            "eleutherai-pythia-160m",
            "pszemraj-flan-t5-large-grammar-synthesis",
            "jean-baptiste-roberta-large-ner-english"
        ],
        "1": [
            "deepmind-language-perceiver",
            "keti-air-ke-t5-large",
            "moritzlaurer-multilingual-minilmv2-l6-mnli-xnli",
            "neulab-codebert-javascript",
            "stanfordaimi-stanford-deidentifier-with-radiology-reports-and-i2b2",
            "salesforce-codet5-large",
            "albert-xlarge-v2",
            "facebook-opt-iml-max-1.3b",
            "qcri-bert-base-multilingual-cased-pos-english",
            "jorgeutd-bert-large-uncased-finetuned-ner",
            "deepset-gbert-base",
            "google-t5-small-lm-adapt",
            "alinear-albert-japanese-v2",
            "microsoft-codegpt-small-java-adaptedgpt2",
            "helsinki-nlp-opus-mt-fi-en",
            "microsoft-biomednlp-pubmedbert-base-uncased-abstract-fulltext",
            "bigscience-test-bloomd-6b3"
        ],
        "2": [
            "gchhablani-fnet-base-finetuned-qnli",
            "yeungnlp-firefly-2b6",
            "allegro-plt5-base",
            "dianx-e5-small-violence-detection",
            "malteos-bloom-6b4-clp-german",
            "elastic-distilbert-base-uncased-finetuned-conll03-english",
            "helsinki-nlp-opus-mt-en-da",
            "google-switch-base-8",
            "zhihan1996-dna-bert-6",
            "google-muril-base-cased",
            "fabriceyhc-bert-base-uncased-amazon-polarity",
            "ai-forever-rugpt3small-based-on-gpt2",
            "kb-bert-base-swedish-cased",
            "alvaroalon2-biobert-genetic-ner",
            "bhadresh-savani-bert-base-go-emotion",
            "google-t5-v1-1-base",
            "baptistedoyen-camembert-base-xnli"
        ]
    },
    "test-westus3": {
        "0": [
            "microsoft-biogpt-large-pubmedqa",
            "mrm8488-bert-mini-finetuned-age-news-classification",
            "thebloke-koala-7b-hf",
            "pile-of-law-legalbert-large-1.7m-2",
            "allenai-led-large-16384-arxiv",
            "google-t5-small-ssm-nq",
            "mrm8488-bert-small-finetuned-squadv2",
            "kiddothe2b-hierarchical-transformer-base-4096",
            "ku-nlp-deberta-v2-tiny-japanese",
            "microsoft-xtremedistil-l12-h384-uncased",
            "allenai-unifiedqa-t5-3b",
            "anferico-bert-for-patents",
            "microsoft-deberta-v3-small",
            "skt-kogpt2-base-v2",
            "cross-encoder-ms-marco-electra-base",
            "allenai-longformer-large-4096-finetuned-triviaqa",
            "t5-large"
        ],
        "1": [
            "helsinki-nlp-opus-mt-en-sla",
            "hello-simpleai-chatgpt-qa-detector-roberta",
            "uer-roberta-base-finetuned-cluener2020-chinese",
            "mrm8488-t5-base-finetuned-wikisql",
            "embeddia-crosloengual-bert",
            "textattack-albert-base-v2-mrpc",
            "deepset-gelectra-base-germanquad",
            "tehvenom-dolly-malion-6b",
            "ramsrigouthamg-t5-large-paraphraser-diverse-high-quality",
            "andreaskoepf-pythia-1.4b-gpt4all-pretrain",
            "lighteternal-sse-tuc-mt-el-en-cased",
            "avichr-hebert-sentiment-analysis",
            "luhua-chinese-pretrain-mrc-roberta-wwm-ext-large",
            "medicalai-clinicalbert",
            "jpwahle-t5-large-word-sense-disambiguation",
            "dbmdz-bert-large-cased-finetuned-conll03-english",
            "rostlab-prot-bert-bfd"
        ],
        "2": [
            "kontur-ai-sbert-punc-case-ru",
            "ingen51-dialogpt-medium-gpt4",
            "plantl-gob-es-roberta-base-bne-sqac",
            "datificate-gpt2-small-spanish",
            "facebook-esm1v-t33-650m-ur90s-3",
            "peerapongch-baikal-sentiment-ball",
            "squirro-albert-base-v2-squad-v2",
            "eleutherai-pythia-70m-deduped-v0",
            "clueai-promptclue-base-v1-5",
            "laituan245-molt5-large-caption2smiles",
            "staka-fugumt-ja-en",
            "bigcode-gpt-bigcode-santacoder",
            "castorini-monot5-base-msmarco-10k",
            "salesforce-codet5-small",
            "voidful-albert-chinese-small",
            "mrm8488-codebert-base-finetuned-detect-insecure-code",
            "sshleifer-distilbart-cnn-12-6"
        ]
    }
}